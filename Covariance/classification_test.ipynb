{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from mne.decoding import CSP\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import mne\n",
    "\n",
    "import moabb\n",
    "from moabb.datasets import BNCI2014_001\n",
    "from moabb.evaluations import WithinSessionEvaluation\n",
    "from moabb.evaluations import CrossSessionEvaluation\n",
    "from moabb.paradigms import LeftRightImagery, MotorImagery  \n",
    "\n",
    "\n",
    "moabb.set_log_level(\"info\")\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (288, 22, 1001)\n",
      "labels_train shape: (288,)\n",
      "X_test shape: (288, 22, 1001)\n",
      "labels_test shape: (288,)\n",
      "Accuracy: 0.74\n",
      "Precision: 0.76\n",
      "Recall: 0.74\n",
      "F1 Score: 0.74\n",
      "Confusion Matrix:\n",
      "[[50  2  0 20]\n",
      " [ 3 60  4  5]\n",
      " [ 8 16 47  1]\n",
      " [15  1  0 56]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        feet       0.66      0.69      0.68        72\n",
      "   left_hand       0.76      0.83      0.79        72\n",
      "  right_hand       0.92      0.65      0.76        72\n",
      "      tongue       0.68      0.78      0.73        72\n",
      "\n",
      "    accuracy                           0.74       288\n",
      "   macro avg       0.76      0.74      0.74       288\n",
      "weighted avg       0.76      0.74      0.74       288\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from mne.decoding import CSP\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Récupérer les données\n",
    "X, labels, meta = paradigm.get_data(dataset=dataset, subjects=[1])\n",
    "\n",
    "# Convertir meta['session'] en array numpy pour une manipulation facile\n",
    "sessions = np.array(meta['session'])\n",
    "\n",
    "# Séparer les indices pour les sessions d'entraînement et de test\n",
    "train_indices = np.where(sessions == '0train')[0]\n",
    "test_indices = np.where(sessions == '1test')[0]\n",
    "\n",
    "# Diviser les données en ensembles d'entraînement et de test\n",
    "X_train, labels_train = X[train_indices], labels[train_indices]\n",
    "X_test, labels_test = X[test_indices], labels[test_indices]\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"labels_train shape:\", labels_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"labels_test shape:\", labels_test.shape)\n",
    "\n",
    "# Créer le pipeline avec CSP et LDA\n",
    "csp = CSP(n_components=8, reg=None, log=True, cov_est='epoch')\n",
    "lda = LDA()\n",
    "\n",
    "pipeline = Pipeline([('CSP', csp), ('LDA', lda)])\n",
    "\n",
    "# Entraîner le modèle\n",
    "pipeline.fit(X_train, labels_train)\n",
    "\n",
    "# Prédire sur l'ensemble de test\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Calculer les métriques\n",
    "accuracy = accuracy_score(labels_test, y_pred)\n",
    "precision = precision_score(labels_test, y_pred, average='macro')\n",
    "recall = recall_score(labels_test, y_pred, average='macro')\n",
    "f1 = f1_score(labels_test, y_pred, average='macro')\n",
    "conf_matrix = confusion_matrix(labels_test, y_pred)\n",
    "class_report = classification_report(labels_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1 Score: {f1:.2f}')\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)\n",
    "print('Classification Report:')\n",
    "print(class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (288, 22, 1001)\n",
      "labels_train shape: (288,)\n",
      "X_test shape: (288, 22, 1001)\n",
      "labels_test shape: (288,)\n",
      "Accuracy: 0.76\n",
      "Precision: 0.77\n",
      "Recall: 0.76\n",
      "F1 Score: 0.76\n",
      "Confusion Matrix:\n",
      "[[52  1  0 19]\n",
      " [ 2 50 15  5]\n",
      " [ 5  5 62  0]\n",
      " [16  0  0 56]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        feet       0.69      0.72      0.71        72\n",
      "   left_hand       0.89      0.69      0.78        72\n",
      "  right_hand       0.81      0.86      0.83        72\n",
      "      tongue       0.70      0.78      0.74        72\n",
      "\n",
      "    accuracy                           0.76       288\n",
      "   macro avg       0.77      0.76      0.76       288\n",
      "weighted avg       0.77      0.76      0.76       288\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyriemann.estimation import Covariances\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "from pyriemann.tangentspace import TangentSpace\n",
    "\n",
    "# Récupérer les données\n",
    "X, labels, meta = paradigm.get_data(dataset=dataset, subjects=[1])\n",
    "\n",
    "# Convertir meta['session'] en array numpy pour une manipulation facile\n",
    "sessions = np.array(meta['session'])\n",
    "\n",
    "# Séparer les indices pour les sessions d'entraînement et de test\n",
    "train_indices = np.where(sessions == '0train')[0]\n",
    "test_indices = np.where(sessions == '1test')[0]\n",
    "\n",
    "# Diviser les données en ensembles d'entraînement et de test\n",
    "X_train, labels_train = X[train_indices], labels[train_indices]\n",
    "X_test, labels_test = X[test_indices], labels[test_indices]\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"labels_train shape:\", labels_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"labels_test shape:\", labels_test.shape)\n",
    "\n",
    "# Créer le pipeline avec Covariances, TangentSpace et SVM\n",
    "cov_estimator = Covariances(estimator='lwf')\n",
    "tangent_space = TangentSpace()\n",
    "scaler = StandardScaler()\n",
    "svm = SVC(kernel='linear')\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('Covariances', cov_estimator),\n",
    "    ('TangentSpace', tangent_space),\n",
    "    ('Scaler', scaler),\n",
    "    ('SVM', svm)\n",
    "])\n",
    "\n",
    "# Entraîner le modèle\n",
    "pipeline.fit(X_train, labels_train)\n",
    "\n",
    "# Prédire sur l'ensemble de test\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Calculer les métriques\n",
    "accuracy = accuracy_score(labels_test, y_pred)\n",
    "precision = precision_score(labels_test, y_pred, average='macro')\n",
    "recall = recall_score(labels_test, y_pred, average='macro')\n",
    "f1 = f1_score(labels_test, y_pred, average='macro')\n",
    "conf_matrix = confusion_matrix(labels_test, y_pred)\n",
    "class_report = classification_report(labels_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1 Score: {f1:.2f}')\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)\n",
    "print('Classification Report:')\n",
    "print(class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (288, 22, 1001)\n",
      "labels_train shape: (288,)\n",
      "X_test shape: (288, 22, 1001)\n",
      "labels_test shape: (288,)\n",
      "Accuracy: 0.70\n",
      "Precision: 0.71\n",
      "Recall: 0.70\n",
      "F1 Score: 0.71\n",
      "Confusion Matrix:\n",
      "[[40  2  1 29]\n",
      " [ 7 55  9  1]\n",
      " [ 5 10 57  0]\n",
      " [20  1  0 51]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        feet       0.56      0.56      0.56        72\n",
      "   left_hand       0.81      0.76      0.79        72\n",
      "  right_hand       0.85      0.79      0.82        72\n",
      "      tongue       0.63      0.71      0.67        72\n",
      "\n",
      "    accuracy                           0.70       288\n",
      "   macro avg       0.71      0.70      0.71       288\n",
      "weighted avg       0.71      0.70      0.71       288\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyriemann.estimation import Covariances\n",
    "from pyriemann.classification import MDM\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Récupérer les données\n",
    "X, labels, meta = paradigm.get_data(dataset=dataset, subjects=[1])\n",
    "\n",
    "# Convertir meta['session'] en array numpy pour une manipulation facile\n",
    "sessions = np.array(meta['session'])\n",
    "\n",
    "# Séparer les indices pour les sessions d'entraînement et de test\n",
    "train_indices = np.where(sessions == '0train')[0]\n",
    "test_indices = np.where(sessions == '1test')[0]\n",
    "\n",
    "# Diviser les données en ensembles d'entraînement et de test\n",
    "X_train, labels_train = X[train_indices], labels[train_indices]\n",
    "X_test, labels_test = X[test_indices], labels[test_indices]\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"labels_train shape:\", labels_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"labels_test shape:\", labels_test.shape)\n",
    "\n",
    "# Créer le pipeline avec Covariances et MDM\n",
    "cov_estimator = Covariances(estimator='lwf')\n",
    "mdm = MDM()\n",
    "\n",
    "pipeline = Pipeline([('Covariances', cov_estimator), ('MDM', mdm)])\n",
    "\n",
    "# Entraîner le modèle\n",
    "pipeline.fit(X_train, labels_train)\n",
    "\n",
    "# Prédire sur l'ensemble de test\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Calculer les métriques\n",
    "accuracy = accuracy_score(labels_test, y_pred)\n",
    "precision = precision_score(labels_test, y_pred, average='macro')\n",
    "recall = recall_score(labels_test, y_pred, average='macro')\n",
    "f1 = f1_score(labels_test, y_pred, average='macro')\n",
    "conf_matrix = confusion_matrix(labels_test, y_pred)\n",
    "class_report = classification_report(labels_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1 Score: {f1:.2f}')\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)\n",
    "print('Classification Report:')\n",
    "print(class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     subject session run\n",
      "0          1  0train   0\n",
      "1          1  0train   0\n",
      "2          1  0train   0\n",
      "3          1  0train   0\n",
      "4          1  0train   0\n",
      "..       ...     ...  ..\n",
      "571        1   1test   5\n",
      "572        1   1test   5\n",
      "573        1   1test   5\n",
      "574        1   1test   5\n",
      "575        1   1test   5\n",
      "\n",
      "[576 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(paradigm.get_data(dataset=dataset, subjects=[1])[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-10 12:47:43,664 WARNING MainThread moabb.paradigms.motor_imagery Choosing from all possible events\n",
      "2024-07-10 12:47:43,677 INFO MainThread moabb.evaluations.base Processing dataset: BNCI2014-001\n",
      "BNCI2014-001-WithinSession:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No hdf5_path provided, models will not be saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-10 12:48:05,732 INFO MainThread moabb.evaluations.base csp+lda | BNCI2014-001 | 1 | 0train: Score 0.754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No hdf5_path provided, models will not be saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-10 12:48:15,600 INFO MainThread moabb.evaluations.base csp+lda | BNCI2014-001 | 1 | 1test: Score 0.711\n",
      "BNCI2014-001-WithinSession: 100%|██████████| 1/1 [00:32<00:00, 32.58s/it]\n"
     ]
    }
   ],
   "source": [
    "dataset = BNCI2014_001()\n",
    "dataset.subject_list = [1]\n",
    "paradigm = MotorImagery()\n",
    "pipeline = make_pipeline(CSP(n_components=8), LDA())\n",
    "evaluation = WithinSessionEvaluation(\n",
    "    paradigm=paradigm,\n",
    "    datasets=[dataset],\n",
    "    overwrite=True,\n",
    "    hdf5_path=None,\n",
    ")\n",
    "results = evaluation.process({\"csp+lda\": pipeline})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(576, 22, 1001)\n",
      "576\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(len(labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
